{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a0645709",
   "metadata": {},
   "source": [
    "---\n",
    "aliases:\n",
    "- /data/neural-nets/python/pytorch/2023/09/13/pytorch-dataloader-collate\n",
    "author: Fabrizio Damicelli\n",
    "badges: false\n",
    "branch: master\n",
    "categories:\n",
    "- pytorch\n",
    "- python\n",
    "- data\n",
    "- neural-nets\n",
    "comments: false\n",
    "date: '2023-09-13'\n",
    "description: \"Understand DataLoader's inner workings and bring your data pipeline to the next level.\"\n",
    "output-file: 2023-09-13-pytorch-dataloader-collate.html\n",
    "title: \"PyTorch DataLoader: Understand and implement a custom collate function\"\n",
    "toc: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb1e8bb-730c-4583-9b9a-14e307f09119",
   "metadata": {},
   "source": [
    "This post contains the code behind this video explanation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e77cb0-8d21-4d70-9e52-d23c516cd59a",
   "metadata": {},
   "source": [
    "{{< video https://youtu.be/JDy58DtZC_g >}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b15ba3-0b21-428e-8043-0b0a7f62d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "import torch\n",
    "from torch import tensor\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06651e38-127f-41dc-b90a-949c56a886ce",
   "metadata": {},
   "source": [
    "Imagine a supervised learning scenario of a classification task with sequential data as features and a binary target.\n",
    "\n",
    "Let's simulate a toy dataset and take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43cd54-3873-42e2-beb1-25a5725c1e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.xs = [\n",
    "            list(range(11, 13)),\n",
    "            list(range(13, 16)),\n",
    "            list(range(16, 21)),\n",
    "            list(range(21, 24)),\n",
    "            list(range(22, 25)),\n",
    "            list(range(25, 30)),\n",
    "        ]\n",
    "        self.ys = [0, 0, 0, 1, 1, 1]\n",
    "        assert len(self.xs) == len(self.ys)\n",
    "    def __len__(self): \n",
    "        return len(self.xs)\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"x\": self.xs[idx],\n",
    "            \"y\": self.ys[idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b90c75-4b95-4ef4-9548-22ccf116da07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [11, 12], 'y': 0}\n",
      "{'x': [13, 14, 15], 'y': 0}\n",
      "{'x': [16, 17, 18, 19, 20], 'y': 0}\n",
      "{'x': [21, 22, 23], 'y': 1}\n",
      "{'x': [22, 23, 24], 'y': 1}\n",
      "{'x': [25, 26, 27, 28, 29], 'y': 1}\n"
     ]
    }
   ],
   "source": [
    "dset = CustomDataset()\n",
    "\n",
    "for item in dset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eb9b5c-2f33-4890-bcaf-f15f0062ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = DataLoader(dset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5470be73-2287-48db-8261-751a058a9e5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dloader:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(batch)\n",
      "File \u001b[0;32m/home/fabrizio/miniconda3/envs/olaf-training-py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/home/fabrizio/miniconda3/envs/olaf-training-py39/lib/python3.9/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/home/fabrizio/miniconda3/envs/olaf-training-py39/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:61\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/fabrizio/miniconda3/envs/olaf-training-py39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/fabrizio/miniconda3/envs/olaf-training-py39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:128\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m/home/fabrizio/miniconda3/envs/olaf-training-py39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:128\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m/home/fabrizio/miniconda3/envs/olaf-training-py39/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:139\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    137\u001b[0m elem_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mnext\u001b[39m(it))\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(elem) \u001b[38;5;241m==\u001b[39m elem_size \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m it):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meach element in list of batch should be of equal size\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    140\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    }
   ],
   "source": [
    "for batch in dloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f71156-d2e1-4e3d-8a8e-acc5c344c49f",
   "metadata": {},
   "source": [
    "## A first solution attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563390e1-32b0-49cb-900c-6ce4bbc9e247",
   "metadata": {},
   "source": [
    "We can refactor our dataset and make it generate items with `x` sequences that all have the same length (a parameter `max_len` that we define beforehand)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e485493-7228-4227-bb8d-99f5889c1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetFixLen(torch.utils.data.Dataset):\n",
    "    def __init__(self, max_len=10):\n",
    "        self.max_len = max_len\n",
    "        self.xs = [\n",
    "            list(range(11, 13)),\n",
    "            list(range(13, 16)),\n",
    "            list(range(16, 21)),\n",
    "            list(range(21, 24)),\n",
    "            list(range(22, 25)),\n",
    "            list(range(25, 30)),\n",
    "        ]\n",
    "        self.ys = [0, 0, 0, 1, 1, 1]\n",
    "        assert len(self.xs) == len(self.ys)\n",
    "    def __len__(self): \n",
    "        return len(self.xs)\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.xs[idx]\n",
    "        pad_len = self.max_len - len(x)\n",
    "        x = x + [0]*pad_len\n",
    "        return {\n",
    "            \"x\": np.array(x),\n",
    "            \"y\": self.ys[idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f879d-522d-46e7-b39c-1b003d5b2805",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = CustomDatasetFixLen(max_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6976dfd1-db0b-481e-9f39-690158018648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': array([11, 12,  0,  0,  0,  0,  0,  0,  0,  0]), 'y': 0}\n",
      "{'x': array([13, 14, 15,  0,  0,  0,  0,  0,  0,  0]), 'y': 0}\n",
      "{'x': array([16, 17, 18, 19, 20,  0,  0,  0,  0,  0]), 'y': 0}\n",
      "{'x': array([21, 22, 23,  0,  0,  0,  0,  0,  0,  0]), 'y': 1}\n",
      "{'x': array([22, 23, 24,  0,  0,  0,  0,  0,  0,  0]), 'y': 1}\n",
      "{'x': array([25, 26, 27, 28, 29,  0,  0,  0,  0,  0]), 'y': 1}\n"
     ]
    }
   ],
   "source": [
    "for item in dset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b31038-87bb-4381-87e2-f3a87b394eec",
   "metadata": {},
   "source": [
    "That works but is wasteful because we will be padding to `max_len` = 10, even when we only need to pad to length 3 (for example, if the batch is formed by the first two items).\n",
    "That could limit the batch size we work with slowing down the training or even lead to unnecessary computations during the forward pass if we just pass our batches without masking. \n",
    "So, ideally, we would like to pad only as much as we need _on each batch_.\n",
    "In other words, we want to dynamically (per batch basis) adapt the padding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e327ff81-c2a4-41aa-b148-cda2da14fb4d",
   "metadata": {},
   "source": [
    "## There must be a better way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dbba12-c3a3-4061-9b9a-48d83114109c",
   "metadata": {},
   "source": [
    "Let's implement our own collate function, i.e. the logic to put items together, that will allow us to the padding on a per batch basis (thus we call it `dynamic_length_collate`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22a8c3-b4be-43cb-9c9d-a84d180302fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_length_collate(batch):\n",
    "    max_len = max(len(item[\"x\"]) for item in batch)\n",
    "    batch_x = []\n",
    "    for item in batch:\n",
    "        pad_len = max_len - len(item[\"x\"])\n",
    "        batch_x.append(item[\"x\"] + [0]*pad_len)\n",
    "    return {\n",
    "        \"x\": tensor(batch_x).type(torch.float),\n",
    "        \"y\": tensor([item[\"y\"] for item in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f188d2c-c18b-431e-b360-c21eda52286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = CustomDataset()  # Use our original dataset, without fix max_len\n",
    "dloader = DataLoader(dset, batch_size=2, shuffle=False,\n",
    "                     collate_fn=dynamic_length_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57da7d-76dd-41cd-b14f-ee6a9c58b94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[11., 12.,  0.],\n",
      "        [13., 14., 15.]]), 'y': tensor([0, 0])}\n",
      "{'x': tensor([[16., 17., 18., 19., 20.],\n",
      "        [21., 22., 23.,  0.,  0.]]), 'y': tensor([0, 1])}\n",
      "{'x': tensor([[22., 23., 24.,  0.,  0.],\n",
      "        [25., 26., 27., 28., 29.]]), 'y': tensor([1, 1])}\n"
     ]
    }
   ],
   "source": [
    "for batch in dloader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f998f7f-f097-46d6-a91a-3fc5102f33aa",
   "metadata": {},
   "source": [
    "That works!\n",
    "\n",
    "For the sake of completeness, let's use our dataloader with the custom collate function and actually feed the data into a (toy) neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b104a5-a16d-48a5-9807-4acc4d4ad95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 9.4607e-04,  4.0929e-03],\n",
      "         [ 5.0468e-04,  5.7644e-03],\n",
      "         [-1.5826e-01,  1.9474e-02]],\n",
      "\n",
      "        [[ 2.6432e-04,  2.6775e-03],\n",
      "         [ 1.3929e-04,  3.5764e-03],\n",
      "         [ 7.2860e-05,  3.3866e-03]]], grad_fn=<TransposeBackward0>), (tensor([[[-1.5826e-01,  1.9474e-02],\n",
      "         [ 7.2860e-05,  3.3866e-03]]], grad_fn=<StackBackward0>), tensor([[[-0.2420,  0.0843],\n",
      "         [ 0.0071,  1.2391]]], grad_fn=<StackBackward0>)))\n"
     ]
    }
   ],
   "source": [
    "# A very toy example of a neural network\n",
    "model = torch.nn.LSTM(input_size=1, hidden_size=2, batch_first=True)\n",
    "\n",
    "for batch in dloader:\n",
    "    bs, seq_len = batch[\"x\"].shape\n",
    "    pred = model(batch[\"x\"].reshape(bs, seq_len, 1))\n",
    "    print(pred)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480884b9-928a-4212-a28f-97de49372fc7",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9a3d37-c25a-45af-8441-129c6cd3e94e",
   "metadata": {},
   "source": [
    "----\n",
    "Any bugs, questions, comments, suggestions? Ping me on [twitter](https://www.twitter.com/fabridamicelli) or drop me an e-mail (fabridamicelli at gmail)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
