{"cells": [{"cell_type": "raw", "id": "a0645709", "metadata": {}, "source": ["---\n", "aliases:\n", "- /posts/2023-06-23-np-array-tobytes.html\n", "author: Fabrizio Damicelli\n", "badges: false\n", "branch: master\n", "categories:\n", "- python\n", "- numpy\n", "- sqlite\n", "comments: false\n", "date: '2024-06-23'\n", "description: Speed up the retrieval of stored vectors.\n", "filters:\n", "- social-share\n", "output-file: np-array-tobytes.html\n", "share:\n", "  description: '\"Efficient Deserialization of Numpy Arrays. Speed up the retrieval\n", "    of stored vectors.\"'\n", "  linkedin: true\n", "  mastodon: true\n", "  permalink: '\"https://fabridamicelli.github.io/posts/np-array-tobytes.html\"'\n", "  reddit: true\n", "  twitter: true\n", "title: Efficient Deserialization of Numpy Arrays\n", "toc: false\n", "\n", "---\n"]}, {"cell_type": "markdown", "id": "6641d5b4-53f5-4915-abe7-b540a6a01e4a", "metadata": {}, "source": ["::: {.callout-note title=\"TL;DR\"}\n", "Numpy's bytes format can be considerably faster than other formats to deserialize.\n", "When storing/retrieving vectors arrays just use the methods `array.tobytes()` and `numpy.frombuffer()` (instead of, for example, `pickle.dumps/loads`).\n", ":::"]}, {"attachments": {}, "cell_type": "markdown", "id": "d6026f1b-ae33-4ae8-ab0d-2b12e038de21", "metadata": {}, "source": ["# The Situation\n", "Let's say you have a bunch of entities, e.g. product-ids of on online shop, for which you have a vector representation (think for example of a word or an image embedding) stored somewhere like a database.\n", "\n", "Now it's time to put your model in production and you need to retrieve the vectors from the database in order to deliver your predictions (for example, you might need to get an embedding representation of product images in order to calculate similarities and show product recommendations).\n", "The most typical (and probably sane thing to do) is to have an [sqlite database](https://sqlite.org/) for storage.\n", "\n", "It turns out, we can store the vectors in different formats and which format we use can **heavily** affect the retrieval (loading and deserialization) speed in our application.\n", "That can be critical if your predictions behind your use-case need to be fast (e.g. under 100ms).\n", "\n", "Let's create some fake data consisting of vectors of length 256 filled with random numbers.\n", "We will use that data to profile the retrieval (from the database) performance of different formats."]}, {"cell_type": "code", "execution_count": 1, "id": "3af0448c-b58f-42ef-b524-2eeab1566beb", "metadata": {}, "outputs": [], "source": ["#| code-fold: true\n", "\n", "from pathlib import Path\n", "import json\n", "import sqlite3\n", "import pickle\n", "\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": 2, "id": "365fdce8-490e-44ae-aefc-2632fe7dbef1", "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0.93501425, 0.70911416, 0.54255025, 0.84465434, 0.92316   ])"]}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": ["vectors = np.random.random(size=(20_000, 256))\n", "data = {f\"id_{i}\": vec for i, vec in enumerate(vectors)}\n", "data[\"id_0\"][:5]"]}, {"cell_type": "markdown", "id": "6bd87f74-e3d5-4c26-88a1-95857ecf2c4e", "metadata": {}, "source": ["## Store Vectors as Text\n", "Our first option is to just dump the numbers into the database as text."]}, {"cell_type": "code", "execution_count": 3, "id": "9338d57c-77a8-458c-88d6-3c8affc21de7", "metadata": {}, "outputs": [], "source": ["def dump_vectors_as_json(data, db_path):\n", "    conn = sqlite3.connect(db_path)\n", "    cur = conn.cursor()\n", "    cur.execute(\n", "    \"\"\"\n", "    CREATE TABLE vectors (\n", "    id TEXT PRIMARY KEY,\n", "    vector TEXT\n", "    )\n", "    \"\"\"\n", "    )\n", "    for pid, vec in data.items():\n", "        db_vec = json.dumps(list(vec))\n", "        cur.execute(\"INSERT INTO vectors VALUES (?,?)\", (pid, db_vec))\n", "        conn.commit()\n", "    conn.close()"]}, {"cell_type": "code", "execution_count": 4, "id": "335874a1-4728-448f-b9da-f66022aaf632", "metadata": {}, "outputs": [], "source": ["path_json = \"/tmp/embeddings-json.db\"\n", "Path(path_json).unlink()  # start fresh\n", "dump_vectors_as_json(data, path_json)"]}, {"cell_type": "markdown", "id": "059a87d2-c2de-4d42-be58-23f0353731e5", "metadata": {}, "source": ["Now let's take a look at the data by querying specific 5000 ids:"]}, {"cell_type": "code", "execution_count": 5, "id": "c6d3ff3f-7025-4df9-b932-5b342581a00f", "metadata": {}, "outputs": [{"data": {"text/plain": ["['id_0', 'id_1', 'id_2', 'id_3', 'id_4']"]}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": ["ids = [f\"id_{i}\" for i in range(5000)]\n", "ids[:5]"]}, {"cell_type": "code", "execution_count": 6, "id": "ea1bcae7-6324-472b-a517-b4ba7fc9155b", "metadata": {}, "outputs": [], "source": ["def load_vectors_from_db(db_path, ids):\n", "    conn = sqlite3.connect(f\"file:{db_path}?mode=ro\", uri=True)\n", "    cur = conn.cursor()\n", "    placeholder = f\"({','.join('?'*len(ids))})\"\n", "    out = cur.execute(\n", "        f\"\"\"\n", "        SELECT * FROM vectors\n", "        WHERE id in {placeholder}\n", "        \"\"\",\n", "        ids\n", "    ).fetchall()\n", "    conn.close() \n", "    return dict(out)"]}, {"cell_type": "code", "execution_count": 9, "id": "f5accefd-fc43-4ae7-b763-f8aebab2b0b7", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["id_0 [0.9350142536057673, 0.7091141633646703, 0.5425502463856475]\n"]}], "source": ["for id_, vec in load_vectors_from_db(path_json,ids).items():\n", "    print(id_, json.loads(vec)[:3])  # show only first 3 values\n", "    break"]}, {"attachments": {}, "cell_type": "markdown", "id": "b283d1e7-7012-43fd-a9c9-10f3283f4687", "metadata": {}, "source": ["Looks fine, but we cannot do much with the values as text, let's convert them back into numpy arrays:"]}, {"cell_type": "code", "execution_count": 10, "id": "d2b27d75-0b87-469f-a1b0-04c3e834a310", "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0.93501425, 0.70911416, 0.54255025, 0.84465434, 0.92316   ,\n", "       0.04012891, 0.38365326, 0.69617891, 0.93489605, 0.32225334])"]}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": ["vecs = {id_: np.array(json.loads(vec)) for id_, vec in load_vectors_from_db(path_json,ids).items()}\n", "vecs[\"id_0\"][:10]"]}, {"cell_type": "markdown", "id": "709429ec-1efa-4d89-8ef7-ad98c9218fd5", "metadata": {}, "source": ["We should wrap that up into a function for later comparison:"]}, {"cell_type": "code", "execution_count": 11, "id": "78894cdd-8ca4-46d2-bc51-4979149e1386", "metadata": {}, "outputs": [], "source": ["def deserialize_json(vec):\n", "    return np.array(json.loads(vec))\n", "\n", "def load_and_deserialize(db_path, ids, deserialize_func):\n", "    loaded = load_vectors_from_db(db_path, ids)\n", "    return {id_: deserialize_func(vec) for id_, vec in loaded.items()}"]}, {"cell_type": "code", "execution_count": 12, "id": "97ef81bd-2f6c-429d-a588-315fa0b9e107", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["id_0 [0.93501425 0.70911416 0.54255025 0.84465434 0.92316   ]\n", "id_1 [0.73054276 0.69741267 0.71045242 0.41007697 0.27032626]\n", "id_2 [0.02500795 0.20845864 0.90890601 0.71998367 0.33240879]\n", "id_3 [0.48994333 0.24024084 0.62285499 0.18298199 0.34209958]\n"]}], "source": ["for k,v in load_and_deserialize(path_json, ids[:4], deserialize_json).items():\n", "    print(k, v[:5])"]}, {"cell_type": "markdown", "id": "5b993d8c-66d3-4f74-bc7c-d28097518d9a", "metadata": {}, "source": ["That's alright, let's quickly check how long it takes for all our 5000 ids:"]}, {"cell_type": "code", "execution_count": 13, "id": "f4433a83-7166-499f-9477-8b76f3438cb4", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["362 ms \u00b1 3.57 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n"]}], "source": ["%%timeit\n", "_ = load_and_deserialize(path_json, ids, deserialize_json)"]}, {"cell_type": "markdown", "id": "149609f1-78ed-429c-a3c9-ff9d46d2acb4", "metadata": {}, "source": ["That might be good enough.\n", "But we can definitely do much better (without paying much of a complexity price)."]}, {"cell_type": "markdown", "id": "6b8a30ad-da35-4ffc-979a-79db6936e619", "metadata": {}, "source": ["## Store Vectors in Binary Format: Pickle \n", "We can store the arrays directly as binary data in the database."]}, {"cell_type": "code", "execution_count": 15, "id": "a4077b05-dd7f-4b7c-80d0-77a18c168f51", "metadata": {}, "outputs": [], "source": ["def dump_vectors_as_pickle_blob(data, db_path):\n", "    conn = sqlite3.connect(db_path)\n", "    cur = conn.cursor()\n", "    cur.execute(\n", "    \"\"\"\n", "    CREATE TABLE vectors (\n", "    id TEXT PRIMARY KEY,\n", "    vector BLOB\n", "    )\n", "    \"\"\"\n", "    )\n", "    for pid, vec in data.items():\n", "        db_vec = pickle.dumps(vec)\n", "        cur.execute(\"INSERT INTO vectors VALUES (?,?)\", (pid, db_vec))\n", "        conn.commit()\n", "    conn.close()"]}, {"cell_type": "code", "execution_count": 16, "id": "3e575c0e-8789-42ba-824f-94a03858c99d", "metadata": {}, "outputs": [], "source": ["path_pickle = \"/tmp/embeddings-pickle.db\"\n", "Path(path_pickle).unlink() # start fresh"]}, {"cell_type": "code", "execution_count": 17, "id": "c2e72509-d09b-4fee-9a34-213e5404cb41", "metadata": {}, "outputs": [], "source": ["dump_vectors_as_pickle_blob(data, path_pickle)"]}, {"cell_type": "markdown", "id": "d79482fa-9333-4f23-b333-950dcfc79b98", "metadata": {}, "source": ["We need another function to deserialize them:"]}, {"cell_type": "code", "execution_count": 18, "id": "a0bbadd4-6139-4832-adf7-36557fa0b9b2", "metadata": {}, "outputs": [], "source": ["def deserialize_pickle(vec):\n", "    return pickle.loads(vec)"]}, {"cell_type": "code", "execution_count": 19, "id": "7ee1bd37-ab5b-419c-afb2-2b8462a3767b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["id_0 [0.93501425 0.70911416 0.54255025 0.84465434 0.92316   ]\n", "id_1 [0.73054276 0.69741267 0.71045242 0.41007697 0.27032626]\n"]}], "source": ["for k,v in load_and_deserialize(path_pickle, ids[:2], deserialize_pickle).items():\n", "    print(k,v[:5])"]}, {"cell_type": "markdown", "id": "f75f1c50-cdd0-46d3-aade-e2800b2f37f6", "metadata": {}, "source": ["What does our clock say?"]}, {"cell_type": "code", "execution_count": 20, "id": "ce08c6fe-9c46-420c-af57-af993621c916", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["40.8 ms \u00b1 2.23 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n"]}], "source": ["%%timeit\n", "\n", "_ = load_and_deserialize(path_pickle, ids, deserialize_pickle)"]}, {"cell_type": "markdown", "id": "610c6c66-ba85-4192-890f-421f1b0163f7", "metadata": {}, "source": ["That's roughly more than 10 times faster.\n", "We're cruising :)\n", "\n", "But we can still do better.\n", "After all we are working with numpy arrays, so we can avoid the pickling path altogether."]}, {"attachments": {}, "cell_type": "markdown", "id": "5f3488b2-7ab6-426c-b42e-e76cc7261615", "metadata": {}, "source": ["## Store Vectors in Binary Format: Numpy Bytes \n", "\n", "Numpy arrays have a method called `.tobytes` that does the job:"]}, {"cell_type": "code", "execution_count": 21, "id": "02213335-bda6-4508-b544-8be67d6301b5", "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0., 1., 2., 3., 4.])"]}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": ["arr = np.arange(5.)\n", "arr"]}, {"cell_type": "code", "execution_count": 22, "id": "e3acd345-e2b5-411c-a656-7838789a9bf0", "metadata": {}, "outputs": [{"data": {"text/plain": ["b'\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf0?\\x00\\x00\\x00\\x00\\x00\\x00\\x00@\\x00\\x00\\x00\\x00\\x00\\x00\\x08@\\x00\\x00\\x00\\x00\\x00\\x00\\x10@'"]}, "execution_count": 22, "metadata": {}, "output_type": "execute_result"}], "source": ["buf = arr.tobytes()\n", "buf"]}, {"cell_type": "code", "execution_count": 23, "id": "87b56d9e-f84e-4b4d-89da-c03bab32a6e5", "metadata": {}, "outputs": [{"data": {"text/plain": ["array([0., 1., 2., 3., 4.])"]}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": ["np.frombuffer(buf)"]}, {"cell_type": "markdown", "id": "3ea69476-dea5-4287-939b-e1b7ba353e65", "metadata": {}, "source": ["::: {.callout-warning}\n", "\n", "When calling `.tobytes()` numpy does not store information about the data type.\n", "The default of `np.frombuffer` is `np.float64`.\n", "But if that does not match your data, the loaded data will be wrong!\n", "Make sure to explicitely pass the `dtype` argument `np.frombuffer(..., dtype=YOUR-TYPE)` for it to work properly.\n", ":::"]}, {"cell_type": "code", "execution_count": 24, "id": "7b14110a-8365-413f-aebf-abde44ea7974", "metadata": {}, "outputs": [], "source": ["def dump_vectors_as_npbytes_blob(data, db_path):\n", "    conn = sqlite3.connect(db_path)\n", "    cur = conn.cursor()\n", "    cur.execute(\n", "    \"\"\"\n", "    CREATE TABLE vectors (\n", "    id TEXT PRIMARY KEY,\n", "    vector BLOB\n", "    )\n", "    \"\"\"\n", "    )\n", "    for pid, vec in data.items():\n", "        db_vec = vec.tobytes()   # <-- HERE\n", "        cur.execute(\"INSERT INTO vectors VALUES (?,?)\", (pid, db_vec))\n", "        conn.commit()\n", "    conn.close()\n", "\n", "def deserialize_npbytes(buf,dtype=np.float64):\n", "    return np.frombuffer(buf, dtype=dtype)"]}, {"cell_type": "code", "execution_count": 25, "id": "e40eb2d0-534b-47fd-a30e-b1c8792c4a61", "metadata": {}, "outputs": [], "source": ["path_npbytes = \"/tmp/embeddings-npbytes\"\n", "Path(path_npbytes).unlink() # start fresh"]}, {"cell_type": "code", "execution_count": 26, "id": "5c2f80a1-f9d4-4b49-b8cb-282c25af3274", "metadata": {}, "outputs": [], "source": ["dump_vectors_as_npbytes_blob(data, path_npbytes)"]}, {"cell_type": "code", "execution_count": 27, "id": "b3951b1e-2e20-47f0-9fdf-04dbb04bdb49", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["id_0 [0.93501425 0.70911416 0.54255025 0.84465434 0.92316   ]\n", "id_1 [0.73054276 0.69741267 0.71045242 0.41007697 0.27032626]\n"]}], "source": ["for k,v in load_and_deserialize(path_npbytes, ids[:2], deserialize_npbytes).items():\n", "    print(k,v[:5])"]}, {"cell_type": "code", "execution_count": 28, "id": "e1d34006-1be7-4835-9c4b-ac5afaab942a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["19.1 ms \u00b1 1.3 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n"]}], "source": ["%%timeit\n", "\n", "_ = load_and_deserialize(path_npbytes, ids, deserialize_npbytes)"]}, {"cell_type": "markdown", "id": "c937c8b9-691d-4bc4-8e09-3999bd636b4f", "metadata": {}, "source": ["That's roughly 1.7 times faster than the pickle version \u2013 for free!\n", "\n", "Let's recap with a side-by-side comparison with a bit larger list of ids to query:"]}, {"cell_type": "code", "execution_count": 29, "id": "52f5ce8d-3275-4842-9c4b-e8502a431fcb", "metadata": {}, "outputs": [], "source": ["ids = [f\"id_{i}\" for i in range(10_000)]"]}, {"cell_type": "code", "execution_count": 30, "id": "941cdf90-2266-4edf-bc1f-3b07985413db", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["729 ms \u00b1 7.49 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n"]}], "source": ["%%timeit\n", "\n", "_ = load_and_deserialize(path_json, ids, deserialize_json)"]}, {"cell_type": "code", "execution_count": 31, "id": "de7bd316-741e-4589-9a6e-db8ff2aea787", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["67.7 ms \u00b1 2.58 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n"]}], "source": ["%%timeit\n", "\n", "_ = load_and_deserialize(path_pickle, ids, deserialize_pickle)"]}, {"cell_type": "code", "execution_count": 32, "id": "e63df43c-0cda-4022-972b-07ecb570beb6", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": ["37.1 ms \u00b1 319 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n"]}], "source": ["%%timeit\n", "\n", "_ = load_and_deserialize(path_npbytes, ids, deserialize_npbytes)"]}, {"cell_type": "markdown", "id": "bc04c36b-b60d-496c-9050-fc8746109ccb", "metadata": {}, "source": ["Sometimes 40, 70 or even 500ms are not important.\n", "But sometimes they are (and can cost significant money).\n", "For example, in the context of high-traffic, real-time recommender systems, pushing down the response time by 20/30 ms (for free!)\n", "is definitely not a bad thing to have."]}, {"cell_type": "markdown", "id": "e12e34ba-338c-4be9-8750-10b3751c208e", "metadata": {}, "source": ["<div style=\"text-align: right; font-size: 40px; font-family: 'Inconsolata', monospace;\">\n", "  /Fin\n", "</div>\n", "    \n", "<div style=\"font-family: 'Inconsolata', monospace;\">\n", "Any bugs, questions, comments, suggestions? Ping me on [twitter](https://www.twitter.com/fabridamicelli) or drop me an e-mail (fabridamicelli at gmail).  \n", "Share this article on your favourite platform:\n", "</div>"]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.9"}}, "nbformat": 4, "nbformat_minor": 5}